1)Hadoop in layman’s term:
		Hadoop Components:
		 1)HDFS(Storage)
		2)Map reduce(Processing)
2)Components of Hadoop Framework:
	Hadoop 1.x:
HDFS:
a)Master daemon:Name mode.
b)Slave Daemon:Datanode
MapReduce:
a)Master Daemon:Job Tracker.
b)Slave Daemon:Task Tracker.

Hadoop 2.x:
HDFS:
a)Master daemon:Name mode.
b)Secondary name node
c)Slave Daemon:Datanode
MapReduce:
a)Master Daemon:Resource manager
b)Slave Daemon:Node Manager.

3)Reasons to learn big data technologies:
Demand for Big Data skills is extremely high and being able to prove your expertise is of essence
•	64% of IT hiring managers rate skilled big data knowledge as having extremely high or high value when rating experience of candiadtes;this is based on a survey by CompTIA
•	According to Forbes,the median advertised salary for professional with Big data expertise is $124,000 a year.
•	IBM,Cisco and Oracle together advertised 26,488 open positions that required Big Data expertise in the last twelve months.



